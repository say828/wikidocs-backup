## 메시지 큐(Message Queue)의 역할: Kafka vs. RabbitMQ 선택 가이드

EDA의 심장부에는 '이벤트 채널', 즉 **메시지 큐 (Message Queue)** 또는 **메시지 브로커(Message Broker)**가 있습니다. 이 브로커가 있기에 생산자와 소비자는 서로를 모른 채 통신할 수 있습니다.

오늘날 MSA 환경에서 가장 널리 사용되는 두 거인은 바로 **RabbitMQ**와 **Apache Kafka**입니다. 둘 다 훌륭한 도구이지만, 설계 철학과 이상적인 사용 사례가 근본적으로 다릅니다. 둘 중 하나를 선택하는 것은 우리 아키텍처의 방향을 결정하는 중요한 기술적 의사결정입니다.

---

### RabbitMQ: "똑똑한 우체국" (Smart Broker)

RabbitMQ는 AMQP(Advanced Message Queuing Protocol)라는 표준 프로토콜을 구현한, 전통적이면서도 매우 강력한 메시지 브로커입니다.

* **비유:** 똑똑하고 체계적인 **'우체국'**
* **동작 방식 ('Smart Broker, Dumb Consumer'):**
    1.  **생산자(Producer)**는 메시지(편지)를 **Exchange(우체국 분류실)**로 보냅니다.
    2.  **Exchange**는 메시지의 **Routing Key(주소)**와 사전에 정의된 규칙을 보고, 이 메시지를 어떤 **Queue(사서함)**로 보낼지 결정합니다. 하나의 메시지를 여러 Queue로 복사해서 보낼 수도 있습니다.
    3.  **소비자(Consumer)**는 특정 **Queue(사서함)**를 구독하고 메시지를 기다립니다.
    4.  **브로커(RabbitMQ)**는 소비자에게 메시지를 **밀어주고(Push)**, 소비자가 "잘 받아서 처리했어"라는 **확인 응답(Ack)**을 보낼 때까지 메시지를 보관합니다. 만약 소비자가 실패하면, 다른 소비자에게 메시지를 다시 전달해 줄 수도 있습니다.
* **장점:**
    * **유연한 라우팅:** Exchange를 통해 매우 복잡하고 정교한 메시지 라우팅 시나리오를 구현할 수 있습니다.
    * **메시지 처리 보장:** 소비자의 처리 성공 여부를 브로커가 직접 관리하므로, 작업(Task)이 유실되지 않도록 보장하는 데 유리합니다.
* **최적의 사용 사례:**
    * 처리 순서가 중요한 **작업 큐(Task Queue)** (예: 동영상 인코딩 요청 분배)
    * 복잡한 규칙에 따라 메시지를 다른 소비자에게 전달해야 하는 경우

### Apache Kafka: "초고속 분산 로그 파일" (Dumb Broker)

Kafka는 원래 LinkedIn에서 대규모 활동 로그를 실시간으로 처리하기 위해 개발되었습니다. 메시지 큐라기보다는 **'분산 커밋 로그(Distributed Commit Log)'** 또는 **'이벤트 스트리밍 플랫폼'**에 가깝습니다.

* **비유:** 모든 출판 기록이 영구적으로 기록되는 거대한 **'도서관의 납품 원장'**
* **동작 방식 ('Dumb Broker, Smart Consumer'):**
    1.  **생산자(Producer)**는 이벤트를 특정 **Topic(책의 장르, 예: '주문')**에 그냥 **추가(Append)**합니다.
    2.  **브로커(Kafka)**는 이벤트를 받아 **Topic**이라는 로그 파일 끝에 순서대로 기록하고 디스크에 저장합니다. 브로커는 누가 이벤트를 읽었는지 전혀 신경 쓰지 않습니다.
    3.  **소비자(Consumer)**는 특정 **Topic**을 구독하고, **자신이 어디까지 읽었는지 '오프셋(Offset)'이라는 책갈피를 스스로 관리**하면서 이벤트를 **가져옵니다(Pull)**.
* **장점:**
    * **압도적인 성능:** 디스크에 순차적으로 쓰기(Sequential I/O) 때문에, 초당 수십만 ~ 수백만 건의 이벤트를 처리할 수 있는 극강의 처리량(Throughput)을 자랑합니다.
    * **데이터 영속성 및 재생(Replay):** 이벤트가 로그처럼 디스크에 저장되므로, 소비자가 장애로 죽었다 살아나도 자신의 '책갈피(오프셋)'부터 다시 읽어 누락 없이 처리할 수 있습니다. 또한, **새로운 소비자**가 나타나 Topic의 **처음부터 모든 이벤트를 다시 읽어서(Replay)** 새로운 분석 시스템을 구축하는 것도 가능합니다.
* **최적의 사용 사례:**
    * 대규모 **이벤트 스트리밍** (예: 클릭 로그, IoT 센서 데이터)
    * 실시간 데이터 파이프라인 및 분석
    * **이벤트 소싱(Event Sourcing)** 및 CQRS 패턴
    * 여러 종류의 소비자가 동일한 이벤트를 각자의 필요에 맞게 소비해야 하는 경우

---

### 선택 가이드: Kafka vs. RabbitMQ

| 특징 | RabbitMQ (Smart Broker) | Apache Kafka (Dumb Broker) |
| :--- | :--- | :--- |
| **패러다임** | 메시지 큐 (작업 전달) | 분산 로그 (이벤트 스트리밍) |
| **라우팅** | 똑똑하고 유연함 (Exchange) | 단순함 (Producer가 Topic 선택) |
| **메시지 관리** | **브로커**가 소비자에게 Push하고 상태 추적 | **소비자**가 Pull하고 스스로 상태(Offset) 추적 |
| **성능** | 좋음 (초당 수만 건) | **매우 뛰어남** (초당 수십만 건 이상) |
| **데이터 보관** | 소비 후 삭제가 기본 | **디스크에 영속 저장이 기본** |
| **이벤트 재생**| 어려움 (기본 기능 아님) | **쉬움 (핵심 기능)** |

### 우리의 선택: Apache Kafka

우리 이커머스 프로젝트에서는 **Apache Kafka**를 선택하겠습니다. 그 이유는 다음과 같습니다.

`OrderPaidEvent`는 단순히 '배송'만을 위한 일회성 '작업'이 아닙니다. 이 이벤트는 비즈니스의 매우 중요한 **'사실(Fact)'**이며, 미래에 다양한 시스템이 이 '사실'을 필요로 할 것입니다.

* `shipping-service`는 배송 처리를 위해
* `notification-service`는 이메일 발송을 위해
* `member-service`는 포인트 적립을 위해
* **(미래) `analytics-service`**는 실시간 매출 분석을 위해
* **(미래) `recommendation-service`**는 사용자 구매 패턴 학습을 위해

이 모든 서비스들이 각자의 필요에 따라 `OrderPaidEvent`를 독립적으로, 그리고 때로는 과거의 이벤트까지 모두 '재생(Replay)'하여 소비해야 할 수 있습니다. 이러한 **'이벤트 스트리밍'** 관점에서, Kafka는 RabbitMQ보다 훨씬 더 강력하고 확장성 있는 아키텍처를 제공합니다.

다음 장에서는 이 강력한 Kafka의 내부 구조를 심층 분석하여, 어떻게 이런 성능이 가능한지 알아볼 것입니다. 그리고 이 장의 다음 절에서는, Kafka든 RabbitMQ든 상관없이 일관된 코드를 작성하게 해주는 스프링의 추상화 계층, `Spring Cloud Stream`을 만나보겠습니다.