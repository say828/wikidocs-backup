## Kafka 컨슈머 랙(Lag) 심화 분석 및 파티션 리밸런싱

Kafka를 사용하는 이벤트 기반 아키텍처에서 가장 중요한 모니터링 지표를 단 하나만 꼽으라면, 그것은 단연 \*\*'컨슈머 랙(Consumer Lag)'\*\*입니다.

-----

### \#\# 컨슈머 랙(Lag)이란 무엇인가?

\*\*랙(Lag)\*\*은 특정 토픽 파티션에 가장 마지막으로 발행된 메시지의 \*\*'프로듀서 오프셋(Producer Offset)'\*\*과, 특정 컨슈머 그룹이 마지막으로 처리하고 커밋한 **'컨슈머 오프셋(Consumer Offset)'** 사이의 \*\*'격차(차이)'\*\*를 의미합니다.

**연속극 따라잡기 비유 📺:**

  * **프로듀서 오프셋:** 방송사가 오늘 **100회**를 방영했습니다. (가장 최신 메시지)
  * **컨슈머 오프셋:** 당신은 어제까지 **95회**까지 시청을 마쳤습니다.
  * **당신의 랙(Lag):** 당신은 방송사를 **5회**만큼 따라잡지 못하고 뒤처져 있습니다 (`100 - 95 = 5`).

컨슈머 랙은 우리의 서비스가 '실시간'에서 얼마나 뒤처져 있는지를 나타내는 가장 직접적인 건강 지표입니다. **랙이 지속적으로 증가**하고 있다는 것은, **이벤트가 소비되는 속도보다 생산되는 속도가 더 빠르다**는 심각한 위험 신호입니다.

-----

### \#\# 랙(Lag) 확인 방법

1.  **Prometheus & Grafana (권장):**
    18장에서 설명했듯이, `kafka_consumer_fetch_manager_records_lag_max` 메트릭을 Grafana 대시보드에 시각화하고, 특정 임계값을 넘으면 Alertmanager가 경고를 보내도록 설정하는 것이 가장 이상적인 방법입니다.

2.  **`kafka-consumer-groups.sh` CLI 도구:**
    즉각적인 상태 확인을 위해, Kafka에 내장된 CLI 도구를 사용할 수 있습니다.

    ```bash
    # Kafka 컨테이너 내부에서 실행
    kafka-consumer-groups.sh --bootstrap-server kafka:9092 \
                             --describe --group shipping-service-group
    ```

    **출력 예시:**

    ```
    GROUP                TOPIC                      PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG        
    shipping-service-group ecommerce.orders.paid    0          1500            1550            50
    shipping-service-group ecommerce.orders.paid    1          1200            1200            0
    shipping-service-group ecommerce.orders.paid    2          1420            1620            200
    ```

    위 출력은 `shipping-service-group`이 `ecommerce.orders.paid` 토픽에 대해 총 `250`의 랙을 가지고 있으며, 특히 2번 파티션에서 처리가 지연되고 있음을 명확히 보여줍니다.

-----

### \#\# 랙(Lag) 증가의 원인과 해결책

랙이 계속해서 증가한다면, 원인은 크게 세 가지 중 하나입니다.

#### 1\. 컨슈머의 처리 속도가 느린 경우

메시지가 들어오는 속도를 컨슈머의 비즈니스 로직 처리 속도가 따라가지 못하는 경우입니다.

  * **원인:**
      * 메시지 하나를 처리하는 데 외부 API를 호출하거나 복잡한 DB 쿼리를 실행하는 등 시간이 오래 걸리는 경우.
      * 컨슈머 Pod에 할당된 CPU나 메모리 리소스가 부족하여 성능이 저하된 경우.
  * **해결책:**
      * **코드 최적화:** 비즈니스 로직을 프로파일링하여 병목 지점을 찾아 개선합니다.
      * **리소스 증설:** 쿠버네티스 Deployment YAML에서 컨슈머 Pod의 `resources.requests`와 `limits`를 늘려줍니다.

#### 2\. 컨슈머가 멈추거나 비정상적인 경우

컨슈머가 아예 메시지를 처리하지 못하고 있는 상황입니다.

  * **원인:**
      * 컨슈머 Pod가 `CrashLoopBackOff` 상태에 빠져 계속 재시작하며, 컨슈머 그룹이 **무한 리밸런싱**에 갇힌 경우. 리밸런싱 중에는 모든 소비가 중단됩니다.
      * 특정 메시지를 처리할 때마다 예외가 발생하여 더 이상 진행하지 못하는, 소위 **'독이 든 메시지(Poison Pill)'** 문제.
  * **해결책:**
      * **Pod 상태 확인:** `kubectl get pods`로 Pod의 상태를 먼저 확인하고, `CrashLoopBackOff`라면 부록 B의 00절 가이드에 따라 원인을 해결합니다.
      * **로그 분석 및 DLQ:** 컨슈머 로그를 확인하여 특정 메시지에서 반복적으로 에러가 발생하는지 확인하고, 해당 메시지를 \*\*데드 레터 큐(DLQ)\*\*로 격리하여 전체 흐름이 막히지 않도록 처리합니다.

#### 3\. 병렬 처리(Parallelism)가 부족한 경우

**가장 흔한 원인 중 하나입니다.** 토픽의 파티션 개수에 비해 컨슈머 인스턴스의 개수가 너무 적은 경우입니다.

  * **원인:**
      * `ecommerce.orders.paid` 토픽은 10개의 파티션을 가지고 있는데, `shipping-service` Deployment의 `replicas`는 `1`로 설정되어 있습니다. 즉, 컨슈머 인스턴스 하나가 10개 파티션의 모든 메시지를 혼자 처리하고 있습니다.
  * **해결책:**
      * **컨슈머 스케일 아웃:** `shipping-service` Deployment의 `replicas` 수를 **파티션 수에 가깝게 늘립니다.** (예: `10`으로)
      * `replicas`를 1에서 10으로 늘리면, Kafka는 **리밸런싱**을 통해 10개의 파티션을 10개의 컨슈머 Pod에 하나씩 재분배합니다. 이론적으로 메시지 처리량이 **10배**로 증가하게 됩니다.
      * **(규칙 복습)** 컨슈머 그룹의 인스턴스 수는 토픽의 파티션 수를 초과할 수 없습니다.

**결론적으로,** 컨슈머 랙은 Kafka 기반 시스템의 가장 중요한 건강 바로미터입니다. 랙이 발생했을 때, CLI와 메트릭을 통해 현상을 관찰하고, '처리 속도', '컨슈머 상태', '병렬 처리'라는 세 가지 관점에서 원인을 체계적으로 분석하여 적절한 조치를 취하는 것은 안정적인 MSA를 운영하는 데 필수적인 역량입니다.