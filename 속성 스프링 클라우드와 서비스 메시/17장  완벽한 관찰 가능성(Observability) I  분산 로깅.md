# 17장: 완벽한 관찰 가능성(Observability) I: 분산 로깅

## 00. MSA 환경에서의 로깅: 왜 stdout 로그만으로는 부족한가?

지금까지 우리는 수많은 마이크로서비스를 성공적으로 개발하고 쿠버네티스에 배포했습니다. 하지만 우리의 시스템이 '동작한다'는 것과, '어떻게 동작하는지 우리가 이해한다'는 것은 완전히 다른 이야기입니다. 프로덕션 환경에서 장애가 발생했을 때, 우리는 시스템 내부를 들여다볼 수 있는 '눈'이 필요합니다. 이것이 바로 **관찰 가능성(Observability)**입니다.

관찰 가능성은 크게 **로깅(Logging), 메트릭(Metrics), 추적(Tracing)**이라는 세 개의 기둥으로 이루어집니다. 이 장에서는 그 첫 번째 기둥인 **'분산 로깅'**에 대해 알아보겠습니다.

---

### 모놀리스 시절의 평화로운 로깅

모놀리스 환경에서 로그를 확인하는 것은 간단했습니다.
1.  서버에 `ssh`로 접속합니다.
2.  `tail -f /var/log/app.log` 명령어를 실행합니다.
3.  하나의 파일에서 모든 비즈니스 흐름(회원 가입 -> 주문 -> 결제)에 대한 로그를 시간 순서대로 확인할 수 있었습니다.

### MSA 환경의 로그 파편화 문제

하지만 MSA 환경에서는 이 방식이 더 이상 통하지 않습니다. `order-service`는 3대의 Pod에, `payment-service`는 2대의 Pod에, `product-service`는 5대의 Pod에 흩어져 실행되고 있다고 상상해 봅시다.

**사건 발생:** 한 고객이 "주문이 실패했는데, 돈은 빠져나갔어요!"라고 문의합니다.

이 문제의 원인을 찾기 위해, 개발자는 다음과 같은 끔찍한 과정을 거쳐야 합니다.

1.  이 고객의 요청이 어떤 `API 게이트웨이` Pod로 들어갔는지 먼저 찾는다.
2.  게이트웨이 로그를 보고, 이 요청이 어떤 `order-service` Pod로 전달되었는지 IP를 추적한다.
3.  해당 `order-service` Pod에 접속(`kubectl exec`)하여 로그를 확인한다.
4.  `order-service` 로그를 보고, 이 주문이 어떤 `payment-service` Pod를 호출했는지 추적한다.
5.  해당 `payment-service` Pod에 접속하여 로그를 확인한다.
6.  `payment-service`는 성공 로그를 남겼는데, `product-service` 호출에서 문제가 생긴 것 같다. 다시 `product-service` Pod 5개를 일일이 돌아다니며 관련 로그를 찾아 헤맨다.

**CSI 과학 수사대 비유 🔬:**
* **모놀리스 로깅:** 하나의 CCTV 영상을 처음부터 끝까지 돌려보는 것과 같습니다.
* **MSA 로깅:** 수십 대의 파편화된 CCTV 조각들을, 시간대와 인물을 맞춰가며 하나의 스토리라인으로 재구성하는 것과 같습니다.

이처럼 각 컨테이너가 출력하는 표준 출력(`stdout`) 로그만으로는, 여러 서비스에 걸쳐 발생하는 복잡한 상호작용의 전체 그림을 파악하는 것이 **불가능에 가깝습니다.**

---

### 해답: 중앙화된 로깅 시스템 (Centralized Logging)



이 문제를 해결하기 위한 유일한 방법은 **모든 마이크로서비스에서 발생하는 로그를 하나의 중앙 집중된 장소로 수집**하는 것입니다.

**동작 방식:**
1.  **로그 수집기 (Log Collector):** 쿠버네티스 클러스터의 각 서버 노드(Node)에는 `Fluentd`나 `Logstash` 같은 로그 수집 에이전트가 설치됩니다. 이 에이전트는 해당 노드에서 실행되는 모든 컨테이너의 `stdout`/`stderr` 로그를 수집합니다.
2.  **로그 저장소 (Log Storage):** 수집된 로그는 검색과 분석에 최적화된 데이터 저장소로 전송됩니다. 가장 대표적인 기술이 바로 **Elasticsearch**입니다.
3.  **로그 시각화 (Log Visualization):** 개발자는 웹 브라우저를 통해 **Kibana**와 같은 시각화 도구에 접속하여, 중앙 저장소에 수집된 모든 로그를 강력한 검색 기능과 대시보드를 통해 분석합니다.

이제 개발자는 더 이상 개별 컨테이너에 접속할 필요가 없습니다. Kibana 대시보드에서 특정 `traceId`나 `orderId`를 검색하는 것만으로, `게이트웨이` -> `주문` -> `결제` -> `상품` 서비스에 걸쳐 발생한 모든 관련 로그를 **시간 순서대로 한 화면에서** 볼 수 있게 됩니다.

이 장에서는 MSA 환경의 필수 생존 기술인 '중앙화된 로깅 시스템'을 구축하기 위해, 로그를 어떻게 '구조화'해야 하는지 배우고, 대표적인 솔루션인 **ELK(Elasticsearch, Logstash, Kibana) 스택**을 우리 이커머스 클러스터에 구축하는 방법을 알아볼 것입니다.