## Kafka 핵심 아키텍처: 토픽(Topic), 파티션(Partition), 그리고 오프셋(Offset)

Kafka의 압도적인 성능과 확장성은 마법이 아니라, **토픽, 파티션, 오프셋**이라는 3가지 핵심 아키텍처 구성요소의 단순하면서도 영리한 상호작용 덕분입니다. 이 세 가지를 이해하는 것이 Kafka를 정복하는 첫걸음입니다.



---

### 1. 토픽 (Topic): 이벤트의 종류를 나누는 카테고리

**토픽**은 Kafka에서 이벤트를 구분하기 위한 가장 기본적인 단위입니다. 데이터베이스의 '테이블(Table)'이나 파일시스템의 '폴더(Folder)'와 유사한 개념으로 생각할 수 있습니다.

* **목적:** 특정 종류의 이벤트들을 그룹화하는 논리적인 '채널' 또는 '스트림'입니다.
* **명명 규칙:** 일반적으로 이벤트의 의미를 담아 `.`으로 구분하여 명명합니다. (예: `ecommerce.orders.paid`, `user.activity.clicks`)
* **역할:**
    * **생산자(Producer)**는 특정 토픽을 지정하여 이벤트를 발행합니다.
    * **소비자(Consumer)**는 특정 토픽을 지정하여 이벤트를 구독합니다.

`order-service`는 `ecommerce.orders.paid` 토픽으로 이벤트를 발행하고, `shipping-service`는 이 토픽을 구독하여 이벤트를 받아가는 구조입니다.

---

### 2. 파티션 (Partition): 병렬 처리와 확장성의 핵심

만약 하나의 토픽이 단순히 하나의 거대한 로그 파일이라면, 그 파일이 저장된 서버 한 대의 디스크 I/O 성능이 전체 시스템의 병목이 될 것입니다. Kafka는 이 문제를 **파티션**으로 해결합니다.

**파티션**은 하나의 토픽을 여러 개로 나누어 저장하는 **'분할된 로그'**입니다.

* **비유:** 하나의 거대한 책(`토픽`)을 여러 개의 **'챕터(`파티션`)'**로 나누는 것과 같습니다. 이 챕터들은 서로 다른 책장(`Kafka 브로커 서버`)에 분산하여 보관할 수 있습니다.
* **동작 방식:**
    * 각 파티션은 그 자체로 독립적인, 순서가 보장되는 큐(Queue)입니다.
    * 생산자는 여러 파티션에 **동시에(in parallel)** 이벤트를 쓸 수 있습니다.
    * 소비자 그룹 내의 여러 소비자는 각기 다른 파티션을 할당받아 **동시에** 이벤트를 읽어갈 수 있습니다.

이 **'병렬 처리'** 구조가 바로 Kafka가 수평적으로 확장(Scale-out)하여 엄청난 처리량을 달성할 수 있는 비결입니다.

#### 메시지 순서와 파티셔닝 키

Kafka는 매우 중요한 보증과 트레이드오프를 가집니다.

> **"Kafka는 '파티션 내에서'의 메시지 순서만 보장한다."**

전체 토픽에 대한 글로벌 순서는 보장하지 않습니다. 하지만 "동일한 주문에 대한 이벤트들(`주문 생성` -> `주문 변경` -> `주문 취소`)"은 반드시 순서대로 처리되어야 합니다. Kafka는 이 문제를 **'파티셔닝 키(Partitioning Key)'**로 해결합니다.

* **생산자가 이벤트를 발행할 때 '키(Key)'를 지정**하면 (예: `orderId`를 키로 지정), Kafka의 기본 파티셔너(Partitioner)는 이 **키의 해시(Hash)값**을 계산하여 특정 파티션을 결정합니다.
* 결과적으로 **동일한 키를 가진 모든 메시지는 항상 동일한 파티션**으로 들어가게 됩니다.
* 따라서 `orderId: 123`에 대한 모든 이벤트는 항상 같은 파티션에 순서대로 기록되고, 소비자는 이 주문에 대한 이벤트를 순서대로 처리할 수 있음을 보장받습니다.

키를 지정하지 않으면, 이벤트는 라운드 로빈(Round-Robin) 방식으로 여러 파티션에 분산되어 저장됩니다.

---

### 3. 오프셋 (Offset): 소비자의 '읽기 위치'를 기록하는 책갈피

**오프셋**은 각 파티션 내에서 메시지의 **고유한 순번(Sequence ID)**을 나타내는 `long` 타입의 숫자입니다 (`0, 1, 2, 3, ...`).

* **비유:** 책의 챕터(`파티션`) 내의 **'페이지 번호'**와 같습니다.
* **소비자의 책임:** Kafka는 "똑똑한 소비자(Smart Consumer)" 모델을 따릅니다. 브로커는 어떤 소비자가 어디까지 읽었는지 전혀 관리하지 않습니다.
* 대신, **소비자 그룹(Consumer Group)이 스스로 "우리는 0번 파티션의 105번 오프셋까지 읽었어"라는 정보를 Kafka에 주기적으로 '커밋(Commit)'**합니다.

이 '오프셋 커밋' 메커니즘 덕분에 Kafka는 극강의 안정성을 제공합니다. 만약 특정 소비자가 처리 도중 장애로 중단되더라도, 다시 시작될 때 Kafka에 저장된 자신의 마지막 커밋 오프셋을 확인하고, **정확히 중단된 그 지점부터** 이벤트를 다시 읽어와 누락 없이 처리할 수 있습니다.

---

**결론적으로,** Kafka의 아키텍처는 다음과 같이 요약할 수 있습니다.

> "생산자는 특정 **토픽**에 이벤트를 발행하고, 이 이벤트는 '키'에 따라 정해진 **파티션**에 **오프셋**과 함께 기록됩니다. 소비자는 각 파티션의 오프셋을 스스로 관리하며 병렬적으로 이벤트를 읽어갑니다."

이 단순하면서도 강력한 세 가지 개념이 Kafka의 모든 것을 뒷받침합니다. 다음 절에서는 생산자와 소비자가 이 아키텍처와 어떻게 상호작용하는지 더 자세히 살펴보겠습니다.