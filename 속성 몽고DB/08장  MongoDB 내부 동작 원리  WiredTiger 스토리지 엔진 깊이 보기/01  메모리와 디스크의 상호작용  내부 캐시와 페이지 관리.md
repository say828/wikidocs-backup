## 01. 메모리와 디스크의 상호작용: 내부 캐시와 페이지 관리

MongoDB 성능의 비밀을 한 문장으로 요약하면 **"디스크 I/O를 얼마나 피하는가?"**입니다. 디스크 접근은 메모리 접근보다 수천 배에서 수만 배 느리기 때문에, 성능이 뛰어난 데이터베이스는 최대한 많은 작업을 메모리 내에서 처리하도록 설계되었습니다. WiredTiger 스토리지 엔진의 심장에는 바로 이 역할을 수행하는 정교한 **내부 캐시(Internal Cache)**가 있습니다.

---

### WiredTiger 내부 캐시의 구조

WiredTiger는 운영체제가 관리하는 파일 시스템 캐시와는 별도로, `mongod` 프로세스 내에 자신만의 독자적인 메모리 캐시 영역을 확보하여 직접 관리합니다.

* **캐시 크기:** 기본적으로 WiredTiger 캐시는 서버에 장착된 **`(RAM - 1GB)의 50%`** 또는 256MB 중 큰 값을 사용하도록 설정됩니다. 예를 들어, 64GB RAM을 가진 서버에서는 약 31.5GB가 WiredTiger의 내부 캐시로 할당됩니다. 이 크기는 설정 파일(`storage.wiredTiger.engineConfig.cacheSizeGB`)을 통해 조정할 수 있으며, MongoDB 서버에 RAM이 많을수록 성능이 향상되는 가장 직접적인 이유입니다.

* **캐시 내용물:** 이 캐시 안에는 크게 세 종류의 데이터가 존재합니다.
    1.  **클린 데이터 (Clean Data):** 디스크의 데이터 파일로부터 읽어온 데이터의 압축되지 않은 원본 복사본입니다. 이 데이터는 디스크의 내용과 완전히 동일하며, 추후 동일한 데이터에 대한 읽기 요청이 들어왔을 때 디스크를 다시 읽지 않고 메모리에서 즉시 응답하기 위한 목적으로 존재합니다.
    2.  **더티 데이터 (Dirty Data):** 쓰기(insert, update) 작업으로 인해 수정되었지만, 아직 디스크의 영구 데이터 파일에는 기록되지 않은 데이터입니다. 이 데이터의 변경 내역은 저널(Journal)에는 기록되어 내구성이 보장되지만, 최종 목적지인 데이터 파일과는 다른 최신 상태를 유지하고 있습니다.
    3.  **인덱스 페이지 (Index Pages):** 도큐먼트 데이터뿐만 아니라, 빠른 쿼리를 위해 자주 사용되는 B-Tree 인덱스의 일부(노드) 또한 캐시에 저장됩니다.

---

### 데이터의 생명주기: 캐시는 어떻게 사용되는가?

#### 읽기 연산의 흐름 ➡️
1.  클라이언트로부터 `find()` 쿼리 요청이 들어옵니다.
2.  WiredTiger는 쿼리에 필요한 인덱스와 도큐먼트 데이터가 **내부 캐시**에 있는지 먼저 확인합니다.
3.  **Cache Hit:** 만약 데이터가 캐시에 존재한다면(캐시 히트), 디스크 접근 없이 즉시 메모리에서 데이터를 읽어 클라이언트에게 반환합니다. **(가장 빠른 경로)**
4.  **Cache Miss:** 만약 데이터가 캐시에 없다면(캐시 미스), WiredTiger는 디스크에 저장된 **데이터 파일** 또는 **인덱스 파일**에서 해당 데이터를 읽어옵니다.
5.  디스크에서 읽어온 데이터는 다음 요청을 위해 **내부 캐시에 적재**됩니다.
6.  읽어온 데이터를 클라이언트에게 반환합니다.

#### 쓰기 연산의 흐름 ⬅️
1.  클라이언트로부터 `updateOne()`과 같은 쓰기 요청이 들어옵니다.
2.  (내구성을 위해) 변경 내역을 디스크의 **저널 파일**에 먼저 기록합니다.
3.  수정할 도큐먼트를 **내부 캐시**에서 찾습니다. (만약 캐시에 없다면 디스크에서 읽어와 캐시에 적재합니다.)
4.  **캐시 안에 있는 도큐먼트**에 변경 사항을 적용합니다. 이제 이 도큐먼트는 '더티' 상태가 됩니다.
5.  클라이언트에게 작업 성공을 알립니다.
6.  이 '더티' 데이터는 다음 **체크포인트(Checkpoint)** 시점이 될 때까지 캐시에 머물다가, 체크포인트가 발생하면 비로소 디스크의 영구 **데이터 파일**에 기록됩니다.

---

### 페이지 관리와 축출(Eviction)

캐시의 크기는 한정되어 있습니다. 만약 캐시가 가득 찬 상태에서 새로운 데이터를 디스크에서 읽어와야 한다면, 기존 캐시 내용 중 일부를 비워 공간을 확보해야 합니다. 이 과정을 **축출(Eviction)**이라고 합니다.

WiredTiger는 LRU(Least Recently Used)와 유사한 알고리즘을 사용하여 캐시에서 가장 오랫동안 사용되지 않은 데이터 페이지(page)를 축출 대상으로 선정합니다.

* **클린 페이지 축출:** 축출 대상이 디스크와 내용이 같은 '클린' 페이지라면, 그냥 메모리에서 지워버리면 되므로 비용이 매우 저렴합니다.
* **더티 페이지 축출:** 하지만 축출 대상이 아직 디스크에 기록되지 않은 변경분을 가진 '더티' 페이지라면, 그냥 버릴 경우 데이터가 유실됩니다. 따라서 WiredTiger는 이 더티 페이지를 축출하기 전에, 먼저 디스크의 데이터 파일에 기록하는 작업을 수행해야만 합니다.

만약 애플리케이션이 자주 사용하는 데이터와 인덱스의 총량, 즉 **워킹셋(Working Set)**의 크기가 WiredTiger 내부 캐시의 크기보다 크다면, 캐시는 끊임없이 새로운 데이터를 읽어오고 오래된 데이터를 축출하는 **'캐시 이탈(cache churn)'** 현상을 겪게 됩니다. 특히 쓰기 작업이 많은 환경에서 '더티' 페이지 축출이 빈번하게 발생하면, 이는 체크포인트와는 별개로 지속적인 디스크 쓰기 I/O를 유발하여 시스템 성능을 크게 저하시킵니다.

결론적으로, 성공적인 MongoDB 운영의 핵심은 **애플리케이션의 워킹셋을 WiredTiger 캐시 안에 최대한 머무르게 하는 것**입니다. 이를 위해 충분한 RAM을 확보하고 캐시 크기를 적절히 설정하는 하드웨어적인 접근과, 쿼리와 인덱스를 최적화하여 워킹셋 자체의 크기를 줄이는 소프트웨어적인 접근이 모두 필요합니다.