## 04. 장애 복구 시나리오: 자동 페일오버(Failover)와 멤버 복구

레플리카 셋의 진정한 가치는 실제 장애 상황에서 어떻게 반응하고 스스로를 치유하는지를 통해 드러납니다. 이번 절에서는 가장 대표적인 장애 시나리오들을 통해, MongoDB의 자동 장애 복구(Failover) 메커니즘이 실제로 어떻게 동작하고, 장애가 발생했던 멤버가 어떻게 다시 정상적으로 복귀하는지 단계별로 분석합니다.

---

### 시나리오 1: 프라이머리 노드 장애 및 자동 페일오버

가장 중요하고 일반적인 장애 시나리오입니다.

* **상황:** 3개의 멤버(노드 A: Primary, 노드 B: Secondary, 노드 C: Secondary)로 구성된 건강한 레플리카 셋이 운영 중입니다.
* **1단계: 장애 발생 💥**
    노드 A(Primary)를 호스팅하는 서버가 갑작스러운 정전으로 다운되거나, `mongod` 프로세스가 예기치 않게 종료됩니다.
* **2단계: 장애 감지 ⏱️**
    노드 B와 C는 노드 A로부터 더 이상 하트비트 신호를 받지 못합니다. 기본 타임아웃인 10초가 지나면, B와 C는 프라이머리가 다운되었다고 판단합니다.
* **3단계: 선거 실시 🗳️**
    B와 C는 즉시 새로운 프라이머리를 선출하기 위한 선거를 시작합니다. 둘 중 Oplog이 더 최신이고, 먼저 후보로 나선 노드 B가 C에게 투표를 요청합니다. C는 B의 데이터가 자신보다 뒤처지지 않았음을 확인하고 찬성 표를 던집니다.
* **4단계: 새로운 프라이머리 등극 👑**
    노드 B는 자기 자신과 C의 표를 합쳐 과반수(3명 중 2표)를 획득하고, 즉시 새로운 프라이머리로 승격됩니다. MongoDB 드라이버는 이 변경을 자동으로 감지하고, 이후의 모든 쓰기 요청을 새로운 프라이머리인 노드 B로 라우팅하기 시작합니다.

**✅ 시스템 영향:** 애플리케이션은 장애 감지와 선거가 진행되는 약 10~12초 동안 일시적으로 쓰기 작업을 수행할 수 없습니다. 하지만 이 짧은 시간이 지나면, 관리자의 개입 없이도 서비스는 자동으로 정상화됩니다. `primaryPreferred`나 `secondaryPreferred` 읽기 설정을 사용했다면, 읽기 작업은 이 시간 동안에도 중단되지 않았을 수 있습니다.

---

### 시나리오 2: 세컨더리 노드 장애 및 복구

* **상황:** 동일한 레플리카 셋에서, 노드 C(Secondary)가 점검을 위해 재부팅됩니다.
* **1단계: 장애 발생 💤**
    노드 C가 오프라인 상태가 됩니다.
* **2단계: 시스템 영향 ✅**
    **서비스 중단이 전혀 없습니다.** 프라이머리(A)와 다른 세컨더리(B)가 여전히 정상 운영 중이며, 과반수(3명 중 2명)가 살아있어 쿼럼(Quorum)이 유지되기 때문입니다. 프라이머리는 쓰기 작업을 계속 처리할 수 있고, `w: "majority"`로 설정된 쓰기 작업도 A와 B의 확인을 통해 성공적으로 완료됩니다. 단, 데이터 복사본이 하나 줄어들어 장애 감내 수준이 일시적으로 낮아진 상태가 됩니다.
* **3단계: 복구 및 재동기화 🔄**
    점검이 끝나고 노드 C의 `mongod` 프로세스가 재시작됩니다.
    * 노드 C는 레플리카 셋에 다시 합류하여 현재 프라이머리인 노드 A에 접속합니다.
    * 자신이 오프라인이었던 시간 동안 프라이머리에 기록된 모든 Oplog 항목들을 요청합니다.
    * 밀린 Oplog를 자신의 데이터셋에 모두 적용하는 **따라잡기(Catching up)** 과정을 시작합니다. 이 동안 노드 C의 상태는 `RECOVERING`이 됩니다.
    * 모든 Oplog 적용이 끝나 프라이머리와 완전히 동기화되면, 노드 C는 다시 건강한 `SECONDARY` 상태로 전환됩니다. 이제 레플리카 셋은 다시 완전한 장애 감내 수준을 회복합니다.

---

### 시나리오 3: 네트워크 파티션 (Network Partition)

네트워크 문제로 인해 레플리카 셋 멤버들이 둘 이상의 그룹으로 분리되는, 더 복잡한 시나리오입니다.

* **상황:** 노드 A(Primary)는 살아있지만, 네트워크 스위치 문제로 노드 B, C와 통신이 두절되었습니다. 하지만 B와 C는 서로 통신이 가능한 상태입니다.
* **결과:**
    * **고립된 파티션 (노드 A):** 노드 A는 레플리카 셋의 과반수와 통신할 수 없음을 인지합니다. 두 개의 프라이머리가 동시에 존재하는 **스플릿 브레인(Split-Brain)** 상황을 방지하기 위해, 노드 A는 스스로 **프라이머리 역할을 포기하고 세컨더리로 강등**됩니다. 이후 모든 쓰기 요청을 거부합니다.
    * **과반수 파티션 (노드 B, C):** 노드 B와 C는 프라이머리(A)와 통신이 두절되었지만, 자신들이 여전히 과반수를 형성하고 있음을 인지합니다. 따라서 둘은 새로운 선거를 실시하여, 그중 하나(예: B)를 **새로운 프라이머리로 선출**합니다.
* **최종 상태:** 네트워크가 분리된 상황에서도, 과반수 멤버가 살아남은 파티션에서 새로운 프라이머리를 선출하여 **쓰기 작업을 중단 없이 계속 처리**할 수 있습니다. 나중에 네트워크 문제가 해결되어 노드 A가 다시 B, C와 통신하게 되면, 자신보다 높은 임기(term)를 가진 새로운 프라이머리 B를 발견하고, 스스로 B의 데이터를 복제하는 세컨더리 역할을 수행하게 됩니다.

이처럼 레플리카 셋 아키텍처는 단순한 서버 장애뿐만 아니라 복잡한 네트워크 장애 상황에서도 데이터의 일관성을 유지하고 서비스의 가용성을 최대한 보장하도록 설계된 매우 견고한 시스템입니다.