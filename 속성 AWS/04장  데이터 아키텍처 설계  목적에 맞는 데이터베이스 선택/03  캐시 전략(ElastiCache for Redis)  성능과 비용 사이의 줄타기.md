## 03. 캐시 전략(ElastiCache for Redis): 성능과 비용 사이의 줄타기

지금까지 우리는 데이터의 성격에 따라 Aurora의 일관성과 DynamoDB의 확장성이라는 각기 다른 집을 마련해 주었다. 그러나 아무리 잘 지어진 집이라도, 매번 필요할 때마다 멀리 있는 본가(Source of Truth)까지 찾아가서 물건을 가져오는 것은 비효율적이다. 특히나 이커머스 플랫폼처럼 동일한 상품 정보, 동일한 카테고리 목록이 초당 수천 번씩 반복적으로 조회되는 환경에서는 더욱 그렇다. 데이터베이스에 가해지는 반복적인 읽기 부하는 시스템 전체의 성능을 저하시키고, 이는 곧 막대한 인프라 비용 상승으로 이어진다.

이 딜레마를 해결하기 위한 기술이 바로 **캐싱(Caching)**이다. 캐싱은 데이터베이스보다 훨씬 빠른 저장소—주로 **인메모리(In-Memory)**—에 자주 접근하는 데이터를 임시로 복사해두는 전략이다. 이는 마치 도서관의 서고(데이터베이스)에서 가장 인기 있는 책 몇 권을 대출 데스크 바로 옆(캐시)에 따로 비치해두는 것과 같다. 대부분의 사람들은 이 책들을 찾으러 굳이 복잡한 서고까지 들어갈 필요가 없으므로, 도서관 전체의 효율은 극적으로 향상된다.

그러나 캐싱은 공짜가 아니다. 데스크에 비치된 책의 정보가 서고의 최신판과 다르다면(데이터 불일치), 잘못된 정보가 사용자에게 전달되는 치명적인 문제가 발생할 수 있다. 캐시를 도입하는 것은 **성능 향상**과 **비용 절감**이라는 달콤한 열매를 얻는 대신, **데이터 일관성**이라는 복잡하고 어려운 문제를 풀어야 하는 아슬아슬한 줄타기를 시작하는 것과 같다. 이 절에서는 AWS의 관리형 캐시 서비스인 **ElastiCache for Redis**를 중심으로, 이 줄타기를 성공적으로 해내기 위한 핵심 전략과 패턴을 탐구한다.

### 캐시의 존재 이유: 속도의 경제학

컴퓨터 과학에서 성능의 차이는 대부분 데이터가 어디에 있느냐에 따라 결정된다. CPU 레지스터에서 데이터를 가져오는 속도와 네트워크 건너편의 디스크에 저장된 데이터를 가져오는 속도는 수백만 배 이상 차이가 난다.



캐시는 바로 이 속도의 격차를 이용하는 기술이다. 디스크 기반의 데이터베이스(Aurora, DynamoDB)에 접근하는 데 수 밀리초(milliseconds)가 걸린다면, RAM(메인 메모리)에 상주하는 인메모리 캐시에 접근하는 데는 수백 마이크로초(microseconds) 이하가 걸린다. 사용자 경험에 직접적인 영향을 미치는 이 응답 속도의 차이가 바로 캐시가 필요한 첫 번째 이유다.

두 번째 이유는 **비용**이다. 데이터베이스의 읽기 용량(Read Capacity)을 늘리는 것은 상대적으로 비싸다. 반복적인 읽기 요청의 99%를 더 저렴한 캐시가 대신 처리해준다면, 우리는 데이터베이스를 훨씬 작은 규모로 운영하면서도 더 높은 성능을 유지할 수 있다. 즉, 캐시는 성능의 가속 페달인 동시에 비용의 브레이크 역할을 하는 것이다.

### AWS ElastiCache for Redis: 단순한 캐시를 넘어서

AWS ElastiCache는 Redis나 Memcached와 같은 인기 있는 오픈소스 인메모리 엔진을 완전 관리형으로 제공하는 서비스다. 우리는 설치, 패치, 백업, 장애 감지 및 복구와 같은 운영 부담 없이 인메모리 데이터 스토어의 강력한 성능을 활용할 수 있다. 이 책에서는 더 풍부한 데이터 구조와 기능을 제공하는 **Redis**를 표준으로 사용한다.

Redis는 단순한 키-값(Key-Value) 저장소가 아니다. **문자열(Strings), 리스트(Lists), 해시(Hashes), 세트(Sets), 정렬된 세트(Sorted Sets)**와 같은 강력하고 다양한 자료구조를 네이티브로 지원한다. 이 덕분에 Redis는 단순 캐싱을 넘어 훨씬 다채로운 역할을 수행할 수 있다.

* **사용자 세션 저장소:** 사용자의 로그인 정보를 데이터베이스가 아닌 Redis의 해시(Hashes)에 저장하면, 모든 요청마다 데이터베이스를 조회할 필요 없이 빠르고 확장 가능한 인증/인가 시스템을 구축할 수 있다.
* **리더보드 및 랭킹:** 게임 점수나 베스트셀러 상품 순위처럼 실시간으로 순위가 바뀌는 데이터는 Redis의 정렬된 세트(Sorted Sets)를 사용하면 단 몇 줄의 코드로 극도로 빠르게 구현할 수 있다.
* **메시지 큐:** Redis의 리스트(Lists) 자료구조를 활용하여 간단한 비동기 작업 처리를 위한 경량 메시지 큐를 구현할 수도 있다.

### 핵심 캐싱 전략: Cache-Aside (Lazy Loading)

가장 보편적으로 사용되는 캐싱 패턴은 **Cache-Aside**, 또는 **지연 로딩(Lazy Loading)**이라 불리는 전략이다. 애플리케이션의 동작 방식은 다음과 같다.



1.  **Read:** 애플리케이션은 데이터를 읽을 때, 먼저 **캐시**에 데이터가 있는지 확인한다.
2.  **Cache Hit:** 데이터가 캐시에 존재하면(Cache Hit), 즉시 그 데이터를 사용자에게 반환한다. 데이터베이스는 전혀 관여하지 않는다.
3.  **Cache Miss:** 데이터가 캐시에 존재하지 않으면(Cache Miss), 애플리케이션은 **데이터베이스(Source of Truth)**에서 데이터를 읽어온다.
4.  **Populate Cache:** 데이터베이스에서 읽어온 데이터를 **캐시에 저장**한다. 이때, 데이터가 캐시에 얼마나 오랫동안 머무를지 **TTL(Time-To-Live)**을 설정하는 것이 중요하다.
5.  **Return:** 데이터를 사용자에게 반환한다.

**Cache-Aside 패턴의 장점:**
* **요청된 데이터만 캐싱:** 실제로 요청된 적이 있는 데이터만 캐시에 저장되므로, 캐시 메모리를 효율적으로 사용할 수 있다.
* **장애 허용성:** 캐시 클러스터에 장애가 발생하더라도, 애플리케이션은 단지 데이터베이스에서 직접 데이터를 읽어오므로 시스템 전체가 중단되지는 않는다(성능은 저하된다).

**고려사항:**
* **캐시 미스 페널티:** 특정 데이터에 대한 최초의 요청은 항상 Cache Miss가 발생하므로, 캐시의 이점을 누릴 수 없다.
* **데이터 정합성:** 캐시에 데이터가 저장된 후 원본 데이터베이스의 데이터가 변경되면, 캐시의 TTL이 만료될 때까지 두 데이터는 불일치 상태, 즉 **오래된 데이터(Stale Data)**가 된다. 이 문제를 해결하기 위해 데이터베이스의 데이터가 변경될 때마다 캐시의 해당 항목을 명시적으로 삭제(Invalidate)하는 전략을 함께 사용해야 한다.

'NextGen Commerce'의 상품 상세 페이지는 Cache-Aside 패턴의 완벽한 적용 사례다. 상품 정보는 자주 바뀌지 않지만, 매우 빈번하게 조회된다. 첫 번째 사용자가 상품 A를 조회하면 Cache Miss가 발생하여 DB에서 정보를 가져와 Redis에 저장한다. 이후의 모든 사용자는 DB를 거치지 않고 Redis에서 직접 초고속으로 상품 정보를 응답받게 된다.

데이터 아키텍처는 이처럼 하나의 정답이 아닌, 여러 조각을 정교하게 맞춰나가는 퍼즐과 같다. 우리는 Aurora의 일관성, DynamoDB의 확장성, 그리고 ElastiCache for Redis의 속도라는 각기 다른 모양의 조각들을 손에 쥐었다. 이제 이 모든 구성 요소들이 서로 안전하고 효율적으로 대화할 수 있도록, 시스템의 혈관과 신경망을 구축할 시간이다. 다음 장에서는 클라우드 위의 나만의 데이터 센터, VPC를 설계하고 트래픽의 흐름을 완벽하게 제어하는 기술을 탐구할 것이다.