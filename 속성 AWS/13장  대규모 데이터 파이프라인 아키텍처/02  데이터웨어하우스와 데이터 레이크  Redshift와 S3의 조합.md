## 02. 데이터웨어하우스와 데이터 레이크: Redshift와 S3의 조합

우리는 Kinesis로 원시 데이터를 수집하고, Glue와 Lambda를 통해 이 데이터를 깨끗하고 의미 있는 정보로 가공했다. 이제 이 정제된 보석과 같은 데이터를 최종 사용자들이 손쉽게 발견하고, 분석하며, 그 가치를 극대화할 수 있는 최종 목적지, 즉 **서빙 계층(Serving Layer)**에 안착시킬 시간이다. 이 최종 목적지는 전통적으로 두 가지 주요한 형태로 발전해왔다: 구조화된 보고와 비즈니스 인텔리전스(BI)를 위한 **데이터웨어하우스(Data Warehouse)**, 그리고 다양한 형태의 데이터를 원본 그대로 저장하며 머신러닝과 데이터 과학을 위한 놀이터가 되어주는 **데이터 레이크(Data Lake)**다.

과거에는 이 둘을 서로 배타적인 선택지로 여기는 '웨어하우스 vs 레이크'의 전쟁이 있었다. 하지만 클라우드 네이티브 시대의 현대적인 데이터 아키텍처는 이 둘을 대립시키는 대신, 각각의 강점을 조화롭게 결합하여 시너지를 창출하는 **'레이크 하우스(Lake House)'**라는 통합된 접근 방식으로 진화하고 있다.

### 데이터웨어하우스 (Amazon Redshift): 질서정연한 중앙 도서관

**데이터웨어하우스**는 비즈니스 분석 및 보고에 최적화된, 고도로 구조화되고 정제된 데이터를 저장하는 중앙 리포지토리다. 이는 마치 주제별로 완벽하게 분류되고 색인된 거대한 중앙 도서관과 같다. 분석가는 SQL이라는 표준 언어를 사용하여, "지난 분기 카테고리별 매출 상위 10개 상품"과 같은 복잡한 비즈니스 질문에 대해 수 초 내에 일관되고 신뢰할 수 있는 답변을 얻을 수 있다.

AWS에서 이 역할을 수행하는 대표적인 서비스가 바로 **Amazon Redshift**다. Redshift는 페타바이트 규모의 데이터를 처리할 수 있도록 설계된 완전 관리형 클라우드 데이터웨어하우스다.

* **핵심 아키텍처 (MPP):** Redshift의 엄청난 성능의 비밀은 **대규모 병렬 처리(Massively Parallel Processing, MPP)** 아키텍처에 있다. 단일 서버가 모든 일을 처리하는 대신, 수백 개의 컴퓨팅 노드(Node)가 쿼리를 작은 조각으로 나누어 동시에 병렬로 처리한 후, 그 결과를 합쳐서 반환한다. 이는 거대한 퍼즐을 수백 명이 함께 맞추는 것과 같아서, 단일 서버로는 수 시간이 걸릴 복잡한 집계 쿼리도 수 초 만에 완료할 수 있다.
* **컬럼 기반 스토리지:** Redshift는 데이터를 행(Row) 단위가 아닌 **열(Column)** 단위로 저장한다. 분석 쿼리는 보통 테이블의 모든 컬럼이 아닌, 몇 개의 특정 컬럼(예: 매출액, 날짜)만 사용한다. 컬럼 기반 스토리지는 필요한 컬럼의 데이터만 디스크에서 읽으므로, I/O를 극적으로 줄여 쿼리 성능을 크게 향상시킨다.
* **최적의 사용 사례:** Tableau, QuickSight와 같은 BI 도구를 연동한 대화형 대시보드, 정기적인 비즈니스 성과 보고, 광고 캠페인 효과 분석 등 **구조화된 데이터를 기반으로 한 SQL 중심의 분석 워크로드**에 가장 이상적이다.

### 데이터 레이크 (S3): 모든 가능성을 품은 거대한 저수지

**데이터 레이크**는 정형, 반정형, 비정형 데이터를 포함한 모든 종류의 데이터를 원본 형식 그대로, 그리고 대규모로 저장하는 중앙 리포지토리다. 이는 가공되지 않은 자연 그대로의 물이 모두 모이는 거대한 저수지와 같다. 지금 당장은 이 물을 어떻게 사용할지 명확한 계획이 없더라도, 미래에 농업용수, 공업용수, 식수 등 어떤 목적으로든 사용할 수 있는 무한한 가능성을 품고 있다.

AWS에서 데이터 레이크의 사실상 표준 기반은 **Amazon S3**다. S3는 거의 무한에 가까운 확장성, 압도적인 내구성, 그리고 매우 저렴한 스토리지 비용을 제공하여, 기업의 모든 데이터를 저장하기 위한 가장 이상적인 플랫폼이다.

* **스키마 온 리드 (Schema-on-Read):** 데이터웨어하우스가 데이터를 저장하기 전에 엄격한 스키마를 정의해야 하는 '쓰기 시 스키마(Schema-on-Write)' 방식인 반면, 데이터 레이크는 데이터를 있는 그대로 먼저 저장하고, 데이터를 읽어서 분석하는 시점에 스키마를 적용하는 **'읽기 시 스키마(Schema-on-Read)'** 방식을 따른다. 이는 스키마 변경에 대한 극도의 유연성을 제공한다.
* **최적의 사용 사례:** 데이터 과학자들이 다양한 가설을 검증하기 위해 원시 데이터를 탐색적으로 분석하거나, 머신러닝 엔지니어들이 이미지, 텍스트, 로그와 같은 비정형 데이터를 사용하여 모델을 훈련시키는 데 필수적인 공간이다.

### 레이크 하우스 아키텍처: Redshift와 S3의 결합

현대적인 데이터 아키텍처의 목표는 이 두 세계를 통합하는 것이다. 데이터 레이크(S3)를 모든 데이터의 **단일 진실 공급원(Single Source of Truth)**으로 삼고, 이 레이크 위에서 필요에 따라 데이터웨어하우스(Redshift)와 다른 분석 서비스들이 데이터를 활용하도록 만드는 것이다.



**Amazon Redshift Spectrum**은 이 '레이크 하우스' 비전을 현실로 만드는 핵심 기술이다. Redshift Spectrum을 사용하면, S3 데이터 레이크에 저장된 수 페타바이트의 데이터를 **Redshift로 로드(Load)할 필요 없이, 그 자리에 있는 그대로 직접 쿼리**할 수 있다. Redshift는 S3에 있는 데이터를 외부에 있는 거대한 테이블처럼 인식하고, 자신의 강력한 MPP 엔진을 사용하여 Redshift 내부의 데이터와 S3의 데이터를 하나의 SQL 쿼리 안에서 **조인(Join)**하는 놀라운 일을 수행할 수 있다.

**'NextGen Commerce'의 레이크 하우스:**
1.  모든 원시 및 처리된 데이터는 S3 데이터 레이크에 파케이 형식으로 저장된다.
2.  가장 자주 사용되고 빠른 성능이 요구되는 핵심적인 데이터(예: 일별 매출 요약)만 **Redshift 클러스터**로 로드한다.
3.  BI 분석가는 Redshift에 접속하여, 내부의 요약 데이터와 Redshift Spectrum을 통해 S3에 있는 방대한 양의 원시 로그 데이터를 **하나의 SQL 쿼리로 조인**하여, 이전에는 불가능했던 깊이 있는 분석을 수행한다.

이처럼 데이터웨어하우스와 데이터 레이크는 더 이상 경쟁 관계가 아니다. S3라는 거대한 데이터의 중력 중심을 두고, Redshift, Athena, SageMaker, QuickSight와 같은 다양한 목적의 분석 서비스들이 위성처럼 주위를 돌며 각자의 임무를 수행하는 것. 이것이 바로 우리가 지향해야 할 유연하고, 확장 가능하며, 비용 효율적인 현대 데이터 플랫폼의 청사진이다.

이제 우리는 데이터라는 조직의 혈액을 흐르게 하는 대동맥, 즉 데이터 파이프라인을 완성했다. 하지만 이 혈액을 얼마나 효율적으로 사용하고 있는지, 그 비용은 누가 어떻게 책임져야 하는지를 정의하는 재무적인 규율이 없다면, 우리의 데이터 플랫폼은 값비싼 장식품으로 전락할 수 있다. 다음 장에서는 기술과 비즈니스를 연결하는 마지막 고리, **FinOps 문화 구축**에 대해 이야기할 것이다.