# 11장: 플랫폼의 눈과 귀: 실전 옵저버빌리티 구축

우리는 10장에 걸쳐, 세상에서 가장 견고하고 안전한 쿠버네티스 요새를 구축하는 방법을 배웠다. GitOps를 통해 모든 변경 사항을 추적하고, RBAC와 네트워크 정책으로 내부의 질서를 확립했으며, 정책 엔진으로 무장한 공급망은 오직 검증된 병사(이미지)만이 요새 안에 들어오도록 허락한다. 우리의 플랫폼은 이제 기술적으로 완벽해 보인다. 하지만 이 완벽한 요새 안에서, 병사들은 지금 어떤 생각을 하고, 어떤 대화를 나누며, 혹시 보이지 않는 곳에서 역병이 돌고 있지는 않은가? 🏰

아무리 튼튼한 요새라도 그 내부 상태를 실시간으로 파악할 수 있는 **정보망**이 없다면, 그것은 눈과 귀가 먼 거인에 불과하다. 어느 날 갑자기 사용자들이 "웹사이트가 느려요!"라고 외칠 때, 우리는 어디서부터 문제를 찾아야 할까? `frontend` 서비스의 CPU 사용량이 급증한 것일까? 아니면 `database`의 디스크 I/O가 병목일까? 혹은, `payment` 서비스가 외부 PG사와 통신하는 과정에서 미세한 지연이 누적되고 있는 것은 아닐까?

이 질문에 답하기 위해, 우리는 전통적인 **모니터링(Monitoring)**의 한계를 넘어서야 한다. 모니터링이 미리 정해진 질문("CPU 사용량이 80%를 넘었는가?")에 답하는 것이라면, **옵저버빌리티(Observability, 관측 가능성)**는 우리가 미처 예상하지 못했던 **"왜(Why)?"**라는 미지의 질문에 답할 수 있는 능력이다. 복잡하고, 동적이며, 예측 불가능한 마이크로서비스 환경에서, 우리는 시스템의 겉으로 드러난 증상뿐만 아니라, 그 내부 상태를 속속들이 탐색하고 질문할 수 있는 힘이 필요하다.

이 장에서는 우리 플랫폼의 눈과 귀, 그리고 신경계를 구축하는 여정을 떠난다. 우리는 옵저버빌리티의 세 가지 핵심 기둥—**로깅, 메트릭, 트레이스**—이 어떻게 서로 유기적으로 연결되어야 하는지를 먼저 이해할 것이다. 그리고 CNCF 생태계의 사실상 표준 도구인 **Prometheus와 Grafana**를 활용하여 플랫폼과 애플리케이션의 모든 성능 지표를 수집하고 시각화하는 방법을 익힐 것이다. 나아가, 모든 파드의 로그를 한곳으로 모으는 **중앙 집중형 로깅 아키텍처**를 설계하고, 마지막으로 마이크로서비스 시대의 가장 어려운 숙제인 서비스 간의 호출 흐름을 추적하는 **분산 추적(Distributed Tracing)**의 세계를 탐험하며, 우리 플랫폼의 모든 움직임을 손금 보듯 들여다볼 수 있는 궁극의 통찰력을 손에 넣을 것이다.

---

## 00. 세 가지 기둥: 로깅, 메트릭, 트레이스의 유기적 연결

옵저버빌리티라는 거대한 사원은 세 개의 단단한 기둥 위에 세워져 있다. 바로 **로깅(Logging)
**, **메트릭(Metrics)**, 그리고 **분산 추적(Distributed Tracing)**이다. 많은 조직들이 이 세 가지를 각각 별개의 도구로 도입하고 독립적인 사일로(silo)로 운영하는 실수를 저지른다. 하지만 이들의 진정한 힘은, 마치 의사가 환자를 진단할 때 청진(메트릭), 문진(로그), 그리고 CT 촬영(트레이스) 결과를 종합하여 결론을 내리듯, 이 세 가지 데이터 소스를 **유기적으로 연결**하여 시스템을 다각적으로 바라볼 때 발휘된다.

1.  **메트릭 (Metrics): 시스템의 맥박과 혈압**
    **메트릭**은 시스템의 상태를 시간의 흐름에 따라 측정한 **숫자 데이터**다. CPU 사용률, 메모리 점유율, 초당 요청 수(RPS), 에러율, 응답 시간(latency) 등이 모두 메트릭에 해당한다. 메트릭은 본질적으로 **집계(aggregation)**된 정보다. "지난 5분간 `user-service`의 평균 응답 시간은 200ms였다"와 같이 시스템의 전반적인 건강 상태와 트렌드를 한눈에 파악하는 데 최적화되어 있다. 마치 의사가 환자의 맥박과 혈압을 재어 전반적인 건강 상태를 빠르게 판단하는 것과 같다.
    * **강점:** 저장 공간 효율이 높고, 쿼리 속도가 빠르다. 경고(Alerting)를 설정하고 장기적인 트렌드를 분석하는 데 이상적이다.
    * **약점:** "왜" 응답 시간이 갑자기 느려졌는지, 어떤 특정 사용자의 요청이 실패했는지와 같은 개별적인 사건의 세부 내용은 알려주지 못한다.

2.  **로깅 (Logging): 환자의 진술과 증상 기록**
    **로그**는 시스템에서 발생한 **개별적이고 불연속적인 이벤트(event)**에 대한 기록이다. "사용자 ID `123`이 로그인에 성공했다"거나, "데이터베이스 연결에 실패했다: connection timeout"과 같은 타임스탬프가 찍힌 텍스트 데이터가 바로 로그다. 로그는 특정 사건이 발생했을 때 그 주변의 풍부한 **컨텍스트(context)**를 제공한다. 의사가 "언제부터, 어디가, 어떻게 아프셨나요?"라고 묻는 문진 기록과도 같다.
    * **강점:** 예측하지 못했던 오류나 특정 상황의 세부 원인을 파악하는 데 필수적이다. 매우 상세한 정보를 담을 수 있다.
    * **약점:** 데이터의 양이 방대하여 저장 비용이 비싸고, 집계나 트렌드 분석을 위한 쿼리는 상대적으로 느리고 복잡하다.

3.  **분산 추적 (Distributed Tracing): 혈액의 흐름을 추적하는 CT 촬영**
    **트레이스**는 마이크로서비스 아키텍처의 복잡성을 위해 태어났다. 트레이스는 **단일 요청(request)**이 시스템에 들어와서, 여러 마이크로서비스(A -> B -> C)를 거쳐 최종 응답을 반환하기까지의 **전체 여정**을 시각적으로 보여주는 데이터다. 각 서비스에서의 작업 단위를 **스팬(Span)**이라고 하며, 이 스팬들이 인과 관계를 가진 트리 구조로 연결되어 하나의 트레이스를 구성한다. 이것은 마치 조영제를 주입하고 CT를 촬영하여, 혈액이 어떤 경로를 통해 흐르며 어느 혈관에서 막히는지를 정확히 보는 것과 같다.
    * **강점:** 전체 시스템의 병목 지점을 정확히 찾아낼 수 있다. 서비스 간의 숨겨진 의존성을 발견하고, 특정 요청이 왜 느렸는지를 마이크로초 단위까지 분석할 수 있다.
    * **약점:** 모든 요청을 추적하는 것은 오버헤드가 크므로 보통 샘플링(sampling) 방식을 사용한다. 애플리케이션 코드에 계측(instrumentation)이 필요하여 도입에 가장 많은 노력이 필요하다.



이 세 기둥은 서로를 보완하며 완벽한 시너지를 낸다.
* **Grafana** 대시보드에서 **메트릭**의 스파이크(예: 에러율 급증)를 발견한다.
* 해당 시간대의 **로그**를 필터링하여, 특정 에러 메시지("Invalid API Key")가 폭증하고 있음을 확인한다.
* 그 로그에 포함된 **`trace_id`**를 클릭하여 **Jaeger**와 같은 분산 추적 시스템으로 이동한다.
* 해당 트레이스를 통해, `auth-service`가 `key-management-service`로부터 응답을 받지 못해 타임아웃이 발생하고 있으며, 이것이 연쇄적으로 모든 상위 서비스에 에러를 전파하고 있음을 한눈에 파악한다.

이것이 바로 진정한 옵저버빌리티가 제공하는 탐정의 경험이다. 이제 우리는 이 세 가지 데이터를 수집하고 연결하기 위한 CNCF의 표준 무기들을 하나씩 장착해 볼 것이다. 가장 먼저, 시스템의 맥박을 재는 Prometheus의 세계로 들어가 보자.