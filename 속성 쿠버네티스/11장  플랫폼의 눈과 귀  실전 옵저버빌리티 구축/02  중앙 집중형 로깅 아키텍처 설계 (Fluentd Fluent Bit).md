## 02\. 중앙 집중형 로깅 아키텍처 설계 (Fluentd/Fluent Bit)

Prometheus와 Grafana가 우리에게 시스템의 '맥박'을 보여주는 망원경이라면, **로깅**은 시스템의 '목소리'를 듣는 현미경이다. 메트릭이 "에러율이 5%로 급증했다"는 사실을 알려준다면, 로그는 "사용자 'alice'의 JWT 토큰이 만료되어 인증에 실패했다"는 구체적인 증언을 들려준다. 이 상세한 증언 없이는 문제의 근본 원인을 찾는 것은 거의 불가능하다.

하지만 쿠버네티스 환경에서 이 목소리를 듣는 것은 결코 간단하지 않다. `kubectl logs <pod-name>` 명령어는 임시적인 디버깅에는 유용하지만, 프로덕션 환경에서는 거의 무용지물이다. 왜냐하면 파드는 덧없는 존재이기 때문이다. 파드가 재시작되거나 삭제되는 순간, 그 파드가 남긴 모든 로그는 영원히 사라진다. 또한, 수백, 수천 개의 파드에서 쏟아지는 로그를 일일이 `kubectl logs`로 추적하는 것은 망망대해에서 바늘을 찾는 것과 같다.

우리가 필요한 것은 모든 파드의 흩어진 목소리를 하나의 거대한 광장으로 모아, 언제든지 검색하고, 분석하고, 연관 관계를 찾을 수 있도록 만드는 \*\*중앙 집중형 로깅 아키텍처(Centralized Logging Architecture)\*\*다. 이 아키텍처의 목표는 명확하다. 개발자와 운영자는 더 이상 로그를 찾기 위해 개별 파드나 노드에 접속할 필요가 없어야 한다.

이 파이프라인은 일반적으로 세 가지 핵심적인 역할을 수행하는 컴포넌트들로 구성된다.

1.  **로그 수집기 (Log Collector): 모든 노드의 목소리를 담는 귀**
    이것은 클러스터의 모든 노드 위에서 **데몬셋(DaemonSet)** 형태로 실행되는 에이전트다. 이 에이전트의 임무는 자신이 실행 중인 노드에서 발생하는 모든 컨테이너 로그를 수집하는 것이다. 쿠버네티스에서 컨테이너 런타임은 모든 파드의 표준 출력(stdout)과 표준 에러(stderr)를 노드의 특정 디렉토리(예: `/var/log/pods/*.log`)에 파일로 기록한다. 로그 수집기는 바로 이 파일들을 감시(tailing)한다. 이 영역의 왕좌를 차지하고 있는 것이 바로 CNCF의 졸업 프로젝트인 **Fluentd**와, 그 경량화된 버전인 **Fluent Bit**다. Fluent Bit는 극도로 가볍고 성능이 뛰어나, 노드 레벨의 에이전트로는 사실상의 표준으로 자리 잡았다.

2.  **로그 수집/처리 장치 (Log Aggregator/Processor): 목소리를 분류하고 정리하는 중앙 교환원**
    모든 노드의 Fluent Bit가 수집한 로그를 최종 저장소로 직접 보내는 것도 가능하지만, 대규모 시스템에서는 중간에 이 로그들을 한번 모아서 처리하는 중앙 처리 계층을 두는 것이 일반적이다. 이 역할 역시 **Fluentd**가 담당하는 경우가 많다. 중앙 Fluentd는 수많은 Fluent Bit로부터 로그를 수신하여, 버퍼링을 통해 일시적인 부하를 흡수하고, 불필요한 로그를 필터링하며, 파드의 메타데이터(네임스페이스, 레이블 등)와 같은 유용한 정보를 추가로 **덧붙여(enrichment)** 로그의 가치를 높이는 역할을 한다.

3.  **로그 저장소/백엔드 (Log Storage/Backend): 모든 대화가 기록되는 거대한 도서관**
    최종적으로 정제된 로그가 저장되고, 우리가 검색하고 분석할 수 있는 데이터베이스다. 이 영역에는 여러 강력한 선택지가 존재한다.

      * **Elasticsearch:** 전통적인 강자. 강력한 전체 텍스트 검색과 분석 기능을 제공하며, Kibana라는 훌륭한 시각화 도구와 함께 **ELK(Elasticsearch, Logstash, Kibana)** 또는 **EFK(Elasticsearch, Fluentd, Kibana)** 스택의 핵심을 이룬다.
      * **Loki:** Grafana Labs에서 만든, Prometheus의 철학을 로깅의 세계로 가져온 신흥 강자다. Loki는 로그의 내용 전체를 인덱싱하는 대신, 로그의 \*\*메타데이터(레이블)\*\*만을 인덱싱한다. 이는 저장 공간을 극적으로 절약하고, Prometheus와 동일한 레이블 기반의 쿼리 언어(**LogQL**)를 사용하여 메트릭과 로그를 매우 자연스럽게 연결할 수 있다는 혁신적인 장점을 제공한다.

이 모든 것을 종합하면, 로그 데이터의 흐름은 다음과 같다.
**애플리케이션 (stdout) → 노드 파일 시스템 → Fluent Bit (DaemonSet) → 중앙 Fluentd (Deployment) → Elasticsearch/Loki**

이 파이프라인의 효율을 극대화하기 위한 마지막, 그러나 가장 중요한 열쇠는 바로 \*\*구조화된 로깅(Structured Logging)\*\*이다. 애플리케이션이 `User login failed for user 'alice'`와 같은 평범한 텍스트가 아니라, 다음과 같은 **JSON** 형식으로 로그를 남기도록 만드는 것이다.

```json
{
  "timestamp": "2025-10-14T11:20:00Z",
  "level": "ERROR",
  "message": "User login failed",
  "user_id": "alice",
  "source_ip": "1.2.3.4",
  "reason": "invalid_credentials"
}
```

이렇게 구조화된 로그는 더 이상 단순한 텍스트가 아니라, `level`, `user_id`, `reason`과 같이 검색하고, 필터링하며, 집계할 수 있는 **데이터**가 된다. 이제 우리는 "지난 1시간 동안 `level`이 `ERROR`이고 `reason`이 `invalid_credentials`인 모든 로그를 보여줘"와 같은 정교한 질문을 던질 수 있게 된다.

이제 우리는 시스템의 맥박(메트릭)을 보고, 그 목소리(로그)를 들을 수 있게 되었다. 하지만 마이크로서비스의 세계에서는 하나의 요청이 여러 서비스에 걸쳐 복잡한 대화를 나누는 경우가 흔하다. `frontend` 서비스에서 발생한 하나의 에러가 사실은 저 깊은 곳에 있는 `auth-service`의 지연 때문일 수 있다. 이 서비스 간의 복잡한 대화의 흐름, 그 전체 여정을 추적하기 위해 우리는 마지막 기둥, 분산 추적의 세계로 들어가야 한다.