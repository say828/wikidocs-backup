## 01\. Prometheus와 Grafana를 활용한 플랫폼 및 애플리케이션 모니터링

옵저버빌리티의 첫 번째 기둥인 메트릭의 세계에서, **Prometheus**는 더 이상 여러 선택지 중 하나가 아니다. 그것은 CNCF의 두 번째 졸업 프로젝트이자, 클라우드 네이티브 환경의 시계열(time-series) 메트릭을 수집하고 조회하는 데 있어 논쟁의 여지가 없는 \*\*사실상의 표준(de facto standard)\*\*이다. Prometheus를 이해하는 것은 현대적인 모니터링 시스템의 언어를 배우는 것과 같다.

Prometheus의 가장 핵심적인 설계 철학은 전통적인 모니터링 시스템과의 **근본적인 패러다임 전환**에 있다. 바로 **`push` 모델이 아닌 `pull` 모델**을 채택했다는 점이다. 과거의 에이전트 기반 시스템들은 각 서버가 자신의 메트릭을 중앙 수집 서버로 밀어 넣는(`push`) 방식이었다. 하지만 파드가 수시로 생성되고 사라지는 쿠버네티스의 동적인 환경에서 이 방식은 치명적인 약점을 가진다. 새로 생긴 파드가 중앙 서버의 주소를 어떻게 알고 메트릭을 보내야 하는가? 중앙 서버는 수천 개의 파드로부터 쏟아지는 데이터를 어떻게 감당할 것인가?

Prometheus는 이 문제를 거꾸로 뒤집었다. Prometheus 서버는 지칠 줄 모르는 **인구조사원**처럼, 주기적으로 클러스터 내의 모든 감시 대상(파드, 노드 등)을 **직접 방문하여** 메트릭을 **가져온다(pull 또는 scrape)**. 이 간단한 발상의 전환은 쿠버네티스 환경에 놀라운 이점을 가져다준다.

  * **중앙 집중화된 제어:** 메트릭 수집의 모든 책임은 Prometheus 서버에 있다. 애플리케이션은 그저 `/metrics`라는 표준화된 HTTP 엔드포인트에 자신의 상태를 텍스트 형식으로 노출하기만 하면 된다. 누가, 언제, 얼마나 자주 자신의 메트릭을 가져가는지 신경 쓸 필요가 없다.
  * **서비스 디스커버리:** Prometheus는 쿠버네티스 API 서버와 직접 통신하여, `prometheus.io/scrape: 'true'`와 같은 특정 어노테이션이 붙은 모든 파드와 서비스를 자동으로 발견한다. 새로운 파드가 생기면 Prometheus는 즉시 그 파드를 자신의 인구조사 목록에 추가하고, 파드가 사라지면 목록에서 자동으로 제거한다. 수동 설정은 전혀 필요 없다.

하지만 쿠버네티스에서 Prometheus를 직접 설치하고 `prometheus.yml` 설정 파일을 수동으로 관리하는 것은 또 다른 안티패턴이다. 현대적인 방식은 이 모든 복잡성을 다시 쿠버네티스다운, 선언적인 방식으로 관리하는 **Prometheus Operator**를 사용하는 것이다. Prometheus Operator는 `ServiceMonitor`와 `PodMonitor`라는 CRD를 도입하여, 모니터링 설정과 애플리케이션 배포를 완벽하게 분리한다.

개발자는 자신의 서비스를 배포할 때, 그저 다음과 같은 `ServiceMonitor` YAML 파일 하나만 함께 배포하면 된다.

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: my-app-monitor
  labels:
    team: my-team # Prometheus Operator가 이 레이블을 보고 ServiceMonitor를 찾는다.
spec:
  selector:
    matchLabels:
      app: my-app # "app: my-app" 레이블을 가진 서비스를 찾아라
  endpoints:
  - port: http # 그 서비스의 'http'라는 이름을 가진 포트를
    path: /metrics # '/metrics' 경로에서
    interval: 15s # 15초마다 긁어가라
```

이제 Prometheus Operator는 이 `ServiceMonitor`의 생성을 감지하고, 이 규칙을 Prometheus 설정에 자동으로 추가한 뒤 리로드해준다. 개발자는 Prometheus의 존재 자체를 신경 쓸 필요 없이, 자신의 애플리케이션에 대한 모니터링을 스스로 정의하고 활성화할 수 있게 된 것이다.

-----

### Grafana: 데이터를 이야기로 만드는 시각화 계기판

Prometheus는 데이터를 수집하고, 저장하며, **PromQL**이라는 강력한 쿼리 언어를 통해 조회하는 데 최적화된 엔진이다. 하지만 이 숫자와 그래프의 원재료들을 인간이 한눈에 이해할 수 있는 아름답고 의미 있는 **이야기**로 만들어주는 것은 바로 **Grafana**의 역할이다.

Grafana는 Prometheus를 완벽한 데이터 소스로 지원하는, 오픈소스 시각화 도구의 제왕이다. 우리는 Grafana를 통해 Prometheus에 PromQL 쿼리를 날리고, 그 결과를 시계열 그래프, 게이지, 표, 히트맵 등 다양한 형태의 패널로 구성하여 **대시보드**라는 하나의 거대한 계기판을 만들 수 있다.

훌륭한 대시보드는 단순히 예쁜 그래프의 나열이 아니다. 그것은 플랫폼과 애플리케이션의 건강 상태를 한눈에 진단하고, 문제의 원인을 드릴다운하여 찾아갈 수 있도록 논리적으로 구성된 **정보의 흐름**이어야 한다. 일반적으로 우리는 두 가지 종류의 대시보드를 구축한다.

1.  **플랫폼 메트릭 (The Infrastructure):** 클러스터 자체의 건강 상태를 보여준다.

      * **Node Exporter**를 통해 수집된 각 노드의 CPU, 메모리, 디스크, 네트워크 사용량.
      * **kube-state-metrics**를 통해 수집된 쿠버네티스 오브젝트의 상태 (디플로이먼트의 복제본 수, 파드의 상태 등).
      * API 서버, 컨트롤러 매니저, 스케줄러 등 컨트롤 플레인 컴포넌트의 성능 지표.

2.  **애플리케이션 메트릭 (The Business):** 실제 서비스의 성능과 비즈니스 가치를 측정한다. Google SRE 팀이 제창한 \*\*네 가지 황금 신호(The Four Golden Signals)\*\*를 측정하는 것이 좋은 출발점이다.

      * **지연 시간 (Latency):** 요청을 처리하는 데 걸리는 시간. 성공한 요청과 실패한 요청을 구분하여 측정해야 한다.
      * **트래픽 (Traffic):** 시스템이 받고 있는 부하의 양. 웹 서비스의 경우 보통 초당 HTTP 요청 수(RPS)로 측정한다.
      * **에러 (Errors):** 실패한 요청의 비율. 모든 에러는 원인을 파악할 수 있도록 기록되어야 한다.
      * **포화도 (Saturation):** 시스템이 얼마나 '꽉 찼는지'를 나타내는 지표. CPU나 메모리 사용률처럼 시스템의 용량에 가장 가까운 자원을 측정한다.

Prometheus와 Grafana의 조합은 우리 플랫폼의 **시각**을 책임지는, 대체 불가능한 관제탑이다. 우리는 이제 시스템의 모든 맥박과 혈압을 실시간으로 볼 수 있게 되었다. 하지만 숫자가 모든 것을 말해주지는 않는다. 시스템이 왜 그런 숫자를 보여주는지에 대한 더 깊은 이야기를 듣기 위해, 우리는 이제 두 번째 기둥인 로깅의 세계로 들어가야 한다.