# 14장: 멀티테넌시와 비용 최적화: 지속 가능한 플랫폼 운영

우리는 서비스 메시를 통해 마이크로서비스 간의 복잡한 상호작용까지 완벽하게 제어하는 기술적 정점에 도달했다. 우리의 플랫폼은 이제 기술적으로 거의 완벽에 가깝다. 하지만 플랫폼이 성공적으로 성장하고, 수십 개의 개발팀과 수백 개의 애플리케이션이 이 공유된 인프라 위에서 공존하기 시작하면서, 우리는 기술만큼이나 중요한 또 다른 차원의 문제, 즉 **'거버넌스(Governance)'와 '경제학(Economics)'**에 직면하게 된다. 

어떻게 하면 각 팀(테넌트, tenant)에게 공정하고 격리된 작업 공간을 제공할 수 있는가? 한 팀의 자원 낭비가 다른 팀의 서비스 안정성에 영향을 미치는 것을 어떻게 막을 것인가? 클라우드 비용 청구서가 매달 최고치를 경신할 때, 우리는 이 비용이 정확히 어디서 발생하고 있는지, 그리고 어떻게 하면 더 현명하게 자원을 사용할 수 있는지 어떻게 알 수 있는가? 이것이 바로 **멀티테넌시(Multi-tenancy)**와 **비용 최적화(Cost Optimization)**라는, 모든 성공한 플랫폼이 반드시 풀어야 할 숙제다. 💰

이 장에서는 이 복잡하고 현실적인 운영의 세계로 들어간다. 우리는 쿠버네티스의 기본 격리 단위인 **네임스페이스(Namespace)**가 왜 완전한 멀티테넌시를 위해서는 충분하지 않은지를 먼저 살펴보고, **vCluster**와 같은 가상 클러스터 기술을 통해 어떻게 더 강력한 격리를 달성할 수 있는지 알아볼 것이다. 나아가, 안개 속에 가려진 쿠버네티스 비용의 실체를 파헤쳐 **가시성(visibility)**을 확보하고, **Karpenter**와 같은 지능적인 오토스케일러를 통해 어떻게 클러스터의 낭비를 근절하는지 배울 것이다. 마지막으로, 이 모든 기술을 '비용'이라는 공통의 언어로 묶어 엔지니어링과 재무, 비즈니스가 함께 협업하는 문화적 혁신, **FinOps**의 세계를 탐험하며 진정으로 지속 가능한 플랫폼을 완성할 것이다.

---

## 00. 네임스페이스 그 이상: 멀티테넌시 구현 아키텍처 비교 (vCluster)

멀티테넌시를 구현하는 가장 첫 번째 단계는 쿠버네티스의 내장 기능인 **네임스페이스(Namespace)**를 활용하는 것이다. 네임스페이스는 단일 물리적 클러스터 안에 여러 개의 논리적인 파티션을 만드는 방법이다. 각 팀에게 고유한 네임스페이스를 할당함으로써, 우리는 다음과 같은 기본적인 격리를 달성할 수 있다.

* **이름 격리:** 팀 A는 `team-a` 네임스페이스 안에서 `my-db`라는 서비스를 만들 수 있고, 팀 B 역시 `team-b` 네임스페이스 안에서 `my-db`라는 전혀 다른 서비스를 만들 수 있다. 이름 충돌이 발생하지 않는다.
* **리소스 격리:** **ResourceQuota** 오브젝트를 사용하여, `team-a` 네임스페이스가 사용할 수 있는 총 CPU, 메모리, 파드 개수를 제한할 수 있다.
* **권한 격리:** RBAC를 통해, 팀 A의 개발자는 오직 `team-a` 네임스페이스의 리소스에만 접근할 수 있도록 권한을 제한할 수 있다.

이것만으로도 많은 경우에 '충분히 좋은' 멀티테넌시를 달성할 수 있다. 하지만 네임스페이스 기반의 멀티테넌시에는 근본적인 한계가 있다. 바로 모든 테넌트가 **동일한 단일 컨트롤 플레인(API 서버, etcd 등)을 공유**한다는 점이다. 이는 다음과 같은 문제를 야기한다.

* **컨트롤 플레인 성능 문제:** 한 테넌트가 악의적이거나 비효율적인 방식으로 API 서버에 엄청난 양의 요청을 보내면, 클러스터 전체의 컨트롤 플레인 성능이 저하되어 다른 모든 테넌트에게 영향을 줄 수 있다.
* **보안 취약점:** 쿠버네티스 자체의 보안 취약점이 발견될 경우, 한 테넌트를 통해 침투한 공격자가 컨트롤 플레인을 공격하여 클러스터 전체를 장악할 위험이 존재한다.
* **클러스터 수준 리소스 충돌:** CRD(Custom Resource Definition), ClusterRole, StorageClass와 같은 클러스터 전역 리소스는 네임스페이스로 격리되지 않는다. 팀 A가 설치한 오퍼레이터의 CRD 버전이 팀 B가 필요로 하는 버전과 충돌할 수 있다.

이러한 '약한 격리(Soft Multi-tenancy)'의 한계를 극복하기 위해 등장한 것이 바로 **가상 클러스터(Virtual Cluster)**라는 개념이며, 이 분야를 선도하는 프로젝트가 **vCluster**다. vCluster의 아이디어는 혁신적이다. "각 테넌트에게 자신만의 가상 컨트롤 플레인을 제공하자!"

vCluster는 다음과 같이 작동한다.
1.  플랫폼 관리자는 물리적인 **호스트 클러스터(Host Cluster)** 위에, 각 테넌트를 위한 vCluster를 배포한다.
2.  이 vCluster는 그 자체로 하나의 **스테이트풀셋(StatefulSet)**으로 실행된다. 이 스테이트풀셋 안에는 테넌트 전용의 API 서버, 컨트롤러 매니저, 그리고 데이터 저장을 위한 SQLite(기본값) 또는 etcd가 모두 포함되어 있다. 즉, **클러스터 안의 클러스터**가 만들어진 것이다.
3.  테넌트(개발자)는 이제 물리 클러스터가 아닌, 자신만의 가상 클러스터 API 서버에 접속한다. 개발자 입장에서는 자신이 완전한 관리자 권한을 가진 완벽하게 깨끗한 쿠버네티스 클러스터를 받은 것처럼 보인다. 그들은 CRD든, ClusterRole이든, 무엇이든 자유롭게 설치하고 실험할 수 있다.
4.  테넌트가 가상 클러스터에 디플로이먼트를 생성하면, vCluster 안에 있는 **싱커(Syncer)**라는 컴포넌트가 이를 감지한다.
5.  싱커는 이 가상 파드를 실제 물리 호스트 클러스터의 파드로 '번역'하여 스케줄링한다. 이때, 실제 파드는 호스트 클러스터의 특정 네임스페이스 안에 격리되어 실행된다.



이 아키텍처는 네임스페이스만으로는 불가능했던 **강력한 격리(Hard Multi-tenancy)**를 제공한다.
* **컨트롤 플레인 격리:** 각 테넌트는 자신만의 API 서버를 가지므로, 한 테넌트의 부하가 다른 테넌트에게 영향을 주지 않는다.
* **클러스터 리소스 격리:** CRD 충돌과 같은 문제가 원천적으로 사라진다.
* **보안 강화:** 개발자는 가상 클러스터의 관리자일 뿐, 물리 호스트 클러스터에는 아무런 직접적인 권한이 없다.

vCluster는 각 팀에게 쿠버네티스의 모든 유연성을 제공하면서도, 플랫폼 팀은 물리 인프라에 대한 중앙 통제권을 잃지 않을 수 있게 해주는, 두 세계의 장점만을 취한 현명한 해결책이다.

이제 우리는 각 팀에게 안전하고 격리된 놀이터를 제공하는 법을 알았다. 하지만 이 놀이터를 사용하는 데 드는 비용은 누가, 어떻게 지불해야 할까? 다음 절에서는 이 복잡한 비용의 문제를 해결하기 위한 여정을 시작한다.