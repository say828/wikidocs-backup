## 02. 멀티 클러스터 애플리케이션 배포 및 네트워킹 패턴

우리는 이제 Cluster API라는 강력한 자동화 공장을 손에 넣었다. 버튼 하나만 누르면, 전 세계 어디에든 우리가 원하는 사양의 쿠버네티스 클러스터를 몇 분 안에 건설할 수 있게 되었다. 하지만 수많은 독립적인 공화국을 건설하는 것과, 이들을 아우르는 하나의 거대한 연방을 운영하는 것은 전혀 다른 차원의 문제다. 흩어진 클러스터들 위에 어떻게 우리의 애플리케이션 군단을 일관되게 배치하고, 이들이 마치 한 국가 안에 있는 것처럼 자유롭게 소통하게 만들 것인가?

이 질문에 대한 해답은 크게 두 가지 영역, 즉 **배포(Deployment)**와 **네트워킹(Networking)**으로 나뉘며, 각각에 대해 서로 다른 철학을 가진 접근법들이 존재한다.

---

### 멀티 클러스터 배포 패턴

**1. Push 모델: 중앙 지휘소에서의 개별 명령**

가장 직관적이고 널리 사용되는 방식은, 하나의 중앙 지휘소(Management Cluster 또는 CI/CD 시스템)에서 각 개별 워크로드 클러스터로 애플리케이션 매니페스트를 **밀어 넣는(Push)** 것이다. 우리가 7장에서 마스터한 GitOps 도구, **Argo CD**는 이러한 모델을 훌륭하게 지원한다.

Argo CD는 여러 개의 외부 클러스터를 자신의 관리 대상으로 등록할 수 있다. 우리는 단일 Argo CD 인스턴스에 다음과 같은 두 개의 서로 다른 `Application` 리소스를 생성할 수 있다.

* `my-app-us-east-1`: `source`는 동일한 Git 저장소를 가리키지만, `destination.server`는 미국 동부 클러스터의 API 서버 주소를 가리킨다.
* `my-app-eu-west-1`: `source`는 같지만, `destination.server`는 유럽 서부 클러스터의 API 서버를 가리킨다.

이 방식은 각 클러스터가 완전히 독립적인 배포 생명주기를 가지므로, 장애 격리에 유리하고 이해하기 쉽다는 장점이 있다. 하지만 애플리케이션과 클러스터의 수가 늘어남에 따라 관리해야 할 `Application` 리소스의 수가 기하급수적으로 증가하는 관리상의 복잡성을 야기한다.

**2. Pull 모델: 연방 정부의 통합 정책**

또 다른 접근법은 여러 클러스터를 하나의 거대한 '가상 클러스터'처럼 취급하고, 애플리케이션을 단 한 번만 선언하면, 중앙 컨트롤 플레인이 정책에 따라 알아서 적절한 클러스터들로 **전파(Propagate)**하는 것이다. **Karmada**나 **KubeVela**와 같은 프로젝트들이 이 영역을 탐구하고 있다.

이 모델에서는 `PropagationPolicy`나 `PlacementRule`과 같은 새로운 종류의 리소스를 통해 "이 애플리케이션을 `region: europe` 레이블을 가진 모든 클러스터에 배포하라" 또는 "전체 클러스터에 걸쳐 총 100개의 복제본을 유지하되, 각 클러스터의 가용 용량에 따라 분배하라"와 같은 고수준의 정책을 선언할 수 있다. 이는 중앙에서의 일관된 관리에는 유리하지만, 추가적인 컨트롤 플레인을 도입해야 하는 복잡성이 있다.

---

### 멀티 클러스터 네트워킹 패턴

배포보다 훨씬 더 어려운 도전이 바로 네트워킹이다. `us-east-1` 클러스터의 파드와 `eu-west-1` 클러스터의 파드는 서로 다른, 격리된 네트워크 공간에 존재한다. 어떻게 이 둘 사이의 벽을 허물고 통신하게 할 것인가?

**1. L3/L4 연결성: 대륙을 잇는 해저 케이블**

가장 근본적인 접근법은 **Submariner**와 같은 도구를 사용하여, 여러 클러스터의 파드 네트워크를 암호화된 터널(IPsec)로 연결하여, 마치 하나의 거대한 평면 네트워크(Flat Network)인 것처럼 보이게 만드는 것이다. 이를 통해 한 클러스터의 파드는 다른 클러스터 파드의 IP 주소로 직접 라우팅이 가능해진다. 이것은 클러스터 간의 기본적인 연결성을 해결해주지만, 서비스 디스커버리 문제는 여전히 남는다.

**2. L7 서비스 디스커버리: 글로벌 주소록**

결국 우리가 원하는 것은 `us-east-1`의 `frontend` 서비스가 `eu-west-1`에 있는 `database` 서비스를 단순히 `database.prod.svc.cluster.local`이라는 익숙한 이름으로 찾아가는 것이다. 이 마법을 실현하는 것이 바로 **멀티 클러스터 서비스 메시(Multi-cluster Service Mesh)**다.

Istio나 Linkerd는 여러 클러스터에 걸쳐 컨트롤 플레인을 확장하고, 각 클러스터의 서비스 정보를 서로 공유하는 메커니즘을 제공한다. 예를 들어, **서비스 미러링(service mirroring)**과 같은 기술을 통해, `eu-west-1`의 `database` 서비스가 `us-east-1` 클러스터 안에 마치 로컬 서비스인 것처럼 가상의 '대리인(proxy)' 서비스로 나타나게 만들 수 있다. `frontend`는 이 로컬 대리인 서비스에게 요청을 보내면, 서비스 메시의 데이터 플레인이 알아서 이 트래픽을 대륙 너머의 실제 `database` 파드로 안전하게 라우팅해준다.

멀티 클러스터는 단일 장애점을 제거하는 대신, '관리의 복잡성'이라는 새로운 괴물을 소환한다. 성공적인 멀티 클러스터 아키텍처는 이 배포와 네트워킹의 문제를 함께 고려하여, 조직의 요구사항에 맞는 적절한 수준의 통합과 격리 사이에서 균형을 찾는 예술이다.

이제 우리는 단일 클러스터의 한계를 넘어, 진정한 글로벌 스케일의 플랫폼을 구축할 수 있는 마지막 무기까지 손에 넣었다. 이로써 쿠버네티스라는 현재의 패러다임 안에서 우리가 할 수 있는 거의 모든 것을 탐험했다. 하지만 기술의 역사는 멈추지 않는다. 마지막으로, 쿠버네티스 다음의 지평선 너머에서 우리를 기다리고 있는 새로운 물결은 무엇인지 조망하며 이 책의 대장정을 마무리하고자 한다.